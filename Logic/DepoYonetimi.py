# ============================================================
#  DepoYonetimi.py â€” VERÄ° YÃ–NETÄ°MÄ° MERKEZÄ°
#
#  Bu dosya:
#    - Cache okuma / yazma
#    - Undo (yedek) dosyasÄ±
#    - M3U kaynak yÃ¶netimi
#    - M3U parser
#    - Mix parser (TARANACAKLINKLER.txt â†’ host/user/pass)
#    - Ãœlke cache yÃ¶netimi
#    - JSON kayÄ±t iÅŸlemleri
#
#  NOT:
#  Bu dosya artÄ±k TARAMA (SCAN) ile ilgili hiÃ§bir fonksiyon iÃ§ermez.
#  Scan motoru Logic/scan_engine.py iÃ§indedir.
# ============================================================
import asyncio
import hashlib
import json
import os
import re
import shutil
import socket
import threading
from urllib.parse import parse_qs, urlparse

import requests
from fastapi import APIRouter

router = APIRouter()

# ============================================================
#  BÃ–LÃœM 1 â€” DOSYA YOLLARI
# ============================================================

CACHE_FILE = "static/cache.txt"
UNDO_FILE = "static/cache.undo"
MIX_FILE = "static/TARANACAKLINKLER.txt"
COUNTRY_DISK_FILE = "static/countries.json"
M3U_SOURCE_FILE = "static/m3u_sources.json"
M3U_CACHE_FILE = "static/m3u_cache.json"
DATA_FILE = "static/data_scan.json"

# ============================================================
#  BÃ–LÃœM 2 â€” KÄ°LÄ°TLER VE Ã–NBELLEKLER
# ============================================================

FILE_LOCK = threading.Lock()
M3U_SOURCE_LOCK = threading.Lock()

COUNTRY_DISK_CACHE = {}
M3U_CACHE = {"sources": {}}

# ============================================================
#  BÃ–LÃœM 3 â€” YARDIMCI FONKSÄ°YONLAR
# ============================================================

def _hash(text: str) -> str:
    """Metni SHA1 hash'e Ã§evirir (10 karakter)."""
    return hashlib.sha1(text.encode("utf-8", errors="ignore")).hexdigest()[:10]


def detect_type(group: str, name: str) -> str:
    """
    M3U iÃ§eriÄŸindeki kanalÄ±n tÃ¼rÃ¼nÃ¼ belirler.
    LIVE / VOD / DIZI / ADULT / KIDS / 4K
    """
    g = (group or "").lower()
    n = (name or "").lower()
    text = (f"{g} {n}").upper()

    if any(x in text for x in ["ADULT", "+18", "XXX", "PINK", "YETIÅžKIN"]):
        return "ADULT"
    if any(x in text for x in ["KIDS", "CHILD", "CARTOON", "Ã‡OCUK", "BEBEK"]):
        return "KIDS"
    if any(x in text for x in ["SERIES", "DÄ°ZÄ°", "DIZI", "SEASON"]) or re.search(r"s\d{1,2}e\d{1,2}|\d+x\d+", n):
        return "DIZI"
    if any(x in text for x in ["VOD", "MOVIE", "FILM", "SINEMA"]) or re.search(r"\b(19|20)\d{2}\b", n):
        return "VOD"
    if any(x in text for x in ["4K", "UHD"]):
        return "4K"

    return "LIVE"

# ============================================================
#  BÃ–LÃœM 4 â€” M3U KAYNAK YÃ–NETÄ°MÄ°
# ============================================================

def load_m3u_sources():
    """M3U kaynak listesini JSON dosyasÄ±ndan okur."""
    if not os.path.exists(M3U_SOURCE_FILE):
        return []
    try:
        with open(M3U_SOURCE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return []


def save_m3u_sources(rows):
    """M3U kaynak listesini JSON olarak kaydeder."""
    with M3U_SOURCE_LOCK:
        try:
            with open(M3U_SOURCE_FILE, "w", encoding="utf-8") as f:
                json.dump(rows, f, ensure_ascii=False, indent=2)
        except:
            pass


# ðŸ“‚ 1. DEÄžÄ°ÅžKENLERÄ° TANIMLAYALIM
COUNTRY_DISK_FILE = "country_cache.json"
COUNTRY_DISK_CACHE = {}


# ============================================================
#  BÃ–LÃœM 5 â€” M3U PARSER
# ============================================================

EXTINF_RE = re.compile(
    r'#EXTINF:.*?(?:group-title="(?P<group>.*?)")?.*?,(?P<name>.*)',
    re.IGNORECASE
)

def parse_m3u(content: str, source_name: str):
    """M3U iÃ§eriÄŸini parÃ§alar ve kanal listesi dÃ¶ner."""
    items = []
    last_extinf = None
    url_counter = {}

    for raw in content.splitlines():
        line = raw.strip()
        if not line or line.startswith("#EXTM3U"):
            continue

        if line.startswith("#EXTINF"):
            m = EXTINF_RE.search(line)
            last_extinf = {
                "group": (m.group("group") if m else "").strip(),
                "name": (m.group("name") if m else "").strip(),
            }
            continue

        if line.startswith("#") or not last_extinf:
            continue

        url = line
        idx = url_counter.get(url, 0) + 1
        url_counter[url] = idx

        items.append({
            "id": _hash(f"{source_name}|{url}|{idx}"),
            "name": f"{last_extinf['name']} ({idx})" if idx > 1 else last_extinf["name"],
            "group": last_extinf["group"],
            "url": url,
            "source": source_name,
            "type": detect_type(last_extinf["group"], last_extinf["name"]),
        })

        last_extinf = None

    return items


def parse_m3u_content(content: str, source_url: str):
    """M3U iÃ§eriÄŸini kaynaÄŸa gÃ¶re iÅŸler."""
    return parse_m3u(content, source_url)

# ============================================================
#  BÃ–LÃœM 6 â€” ONLINE LÄ°NK AVCISI
# ============================================================

def fetch_online_links():
    """
    Ä°nternetten otomatik Xtream linkleri toplar.
    SonuÃ§larÄ± TARANACAKLINKLER.txt dosyasÄ±na ekler.
    """
    sources = [
        "https://iptv-org.github.io/iptv/index.m3u",
        "https://raw.githubusercontent.com/iptv-org/iptv/master/streams/tr.m3u",
        "https://raw.githubusercontent.com/Free-IPTV/Countries/master/Turkey.m3u"
    ]

    target_path = MIX_FILE
    unique_links = set()

    for url in sources:
        try:
            r = requests.get(url, timeout=10, verify=False)
            if r.status_code == 200:
                found = re.findall(
                    r"(https?://[^/:\s]+(?::\d+)?)/(?:get\.php\?username=|live/|movie/|series/|player_api\.php\?username=)"
                    r"([^/&?]+)[/&?](?:password=)?([^/&?.\s]+)",
                    r.text
                )
                for item in found:
                    unique_links.add(f"{item[0]}|{item[1]}|{item[2]}")
        except:
            continue

    if not unique_links:
        return 0

    existing = set()
    if os.path.exists(target_path):
        with open(target_path, "r", encoding="utf-8") as f:
            existing = {line.strip() for line in f if line.strip()}

    new_added = 0
    with open(target_path, "a", encoding="utf-8") as f_out:
        for l in unique_links:
            if l not in existing:
                f_out.write(l + "\n")
                new_added += 1

    return new_added

# ============================================================
#  BÃ–LÃœM 7 â€” CACHE / JSON KAYIT Ä°ÅžLEMLERÄ°
# ============================================================

def save_scan_to_json(rows):
    """Tarama sonuÃ§larÄ±nÄ± JSON dosyasÄ±na kaydeder."""
    try:
        with open(DATA_FILE, "w", encoding="utf-8") as f:
            json.dump(rows, f, ensure_ascii=False, indent=2)
        print(f"âœ… Tarama sonuÃ§larÄ± {DATA_FILE} dosyasÄ±na kaydedildi.")
    except Exception as e:
        print(f"âŒ JSON kayÄ±t hatasÄ±: {e}")


def save_cache(rows):
    """
    Cache listesini hem TXT hem JSON olarak kaydeder.
    TXT â†’ cache.txt
    JSON â†’ data.json (arayÃ¼z iÃ§in)
    """
    with FILE_LOCK:
        try:
            with open(CACHE_FILE, "w", encoding="utf-8") as f:
                for r in rows:
                    f.write(f"{r['host']}|{r['user']}|{r['pass']}|{r['max']}|{r['days']}|{r['country']}\n")

            with open("static/data.json", "w", encoding="utf-8") as f:
                json.dump({"rows": rows}, f, ensure_ascii=False)

        except Exception as e:
            print(f"âŒ Cache kayÄ±t hatasÄ±: {e}")


def load_cache():
    """cache.txt dosyasÄ±nÄ± okuyup satÄ±rlarÄ± dict listesi olarak dÃ¶ner."""
    rows = []
    if not os.path.exists(CACHE_FILE):
        return rows

    with FILE_LOCK:
        try:
            with open(CACHE_FILE, "r", encoding="utf-8", errors="ignore") as f:
                for line in f:
                    parts = line.strip().split("|")
                    if len(parts) == 6:
                        rows.append({
                            "host": parts[0],
                            "user": parts[1],
                            "pass": parts[2],
                            "max": int(parts[3]),
                            "days": int(parts[4]),
                            "country": parts[5],
                        })
        except:
            pass

    return rows

# ============================================================
#  BÃ–LÃœM 8 â€” M3U / URL YARDIMCILARI
# ============================================================

def normalize_m3u_url(url: str) -> str:
    """URL iÃ§indeki boÅŸluklarÄ± temizler."""
    return url.strip().replace(" ", "") if url else ""


def extract_url(text):
    """Metin iÃ§inden URL Ã§eker."""
    match = re.search(r'(https?://[^\s<>"\']+)', text)
    return match.group(1) if match else None





def parse_mix():
    out = []
    seen = set()
    files = ["static/TARANACAKLINKLER.txt", "static/GUNLUK_INDIRILENLER.txt"]
    lines = []

    for f in files:
        if os.path.exists(f):
            with open(f, "r", encoding="utf-8", errors="ignore") as fp:
                lines.extend(fp.read().splitlines())

    def add(host, user, passwd, maxv=1):
        if not host or not user or not passwd:
            return
        if not host.startswith("http"):
            host = "http://" + host
        uo = urlparse(host)
        final = f"{uo.scheme}://{uo.netloc}"
        key = f"{final}|{user}|{passwd}"
        if key not in seen:
            seen.add(key)
            out.append({
                "host": final,
                "user": user,
                "pass": passwd,
                "max": int(maxv),
                "days": 0,
                "country": "xx"
            })

    i = 0
    L = len(lines)

    while i < L:
        l = lines[i].strip()

        # ---------------------------------------------------------
        # 1) GET.PHP / PLAYER_API
        # ---------------------------------------------------------
        if "get.php" in l or "player_api" in l:
            url = extract_url(l)
            if url:
                uo = urlparse(url)
                q = parse_qs(uo.query)
                u = q.get("username", [""])[0]
                p = q.get("password", [""])[0]
                if u and p:
                    add(f"{uo.scheme}://{uo.netloc}", u, p)
            i += 1
            continue

        # ---------------------------------------------------------
        # 2) Tek satÄ±r pipe formatÄ±
        # ---------------------------------------------------------
        if "|" in l:
            parts = l.split("|")
            if len(parts) >= 3:
                add(parts[0].strip(), parts[1].strip(), parts[2].strip())
                i += 1
                continue

        # ---------------------------------------------------------
        # 3) HOST= USER= PASS= formatÄ±
        # ---------------------------------------------------------
        if l.lower().startswith("host="):
            host = l.split("=", 1)[1].strip()
            user = ""
            passwd = ""

            if i + 1 < L and lines[i+1].lower().startswith("user"):
                user = lines[i+1].split("=", 1)[1].strip()

            if i + 2 < L and lines[i+2].lower().startswith("pass"):
                passwd = lines[i+2].split("=", 1)[1].strip()

            if host and user and passwd:
                add(host, user, passwd)
                i += 3
                continue

        # ---------------------------------------------------------
        # 4) user: test pass: 1234 tek satÄ±r formatÄ±
        # ---------------------------------------------------------
        if "user:" in l.lower() and "pass:" in l.lower():
            host = lines[i-1].strip() if i > 0 else ""
            u = re.search(r"user:\s*([^\s]+)", l, re.I)
            p = re.search(r"pass:\s*([^\s]+)", l, re.I)
            if host and u and p:
                add(host, u.group(1), p.group(1))
                i += 1
                continue

        # ---------------------------------------------------------
        # 5) host user pass boÅŸluklu format
        # ---------------------------------------------------------
        if " " in l and l.count(" ") == 2 and not l.startswith("#"):
            parts = l.split()
            if len(parts) == 3 and "." in parts[0]:
                add(parts[0], parts[1], parts[2])
                i += 1
                continue

        # ---------------------------------------------------------
        # 6) Panel formatÄ±
        # ---------------------------------------------------------
        if l.lower().startswith("panel:"):
            host = l.split(":", 1)[1].strip()
            user = ""
            passwd = ""

            if i + 1 < L:
                l2 = lines[i+1].strip()
                if l2.lower().startswith("kullanÄ±cÄ±") or l2.lower().startswith("kullanici"):
                    user = l2.split(":", 1)[1].strip()

            if i + 2 < L:
                l3 = lines[i+2].strip()
                if l3.lower().startswith("ÅŸifre") or l3.lower().startswith("sifre"):
                    passwd = l3.split(":", 1)[1].strip()

            if host and user and passwd:
                add(host, user, passwd)
                i += 3
                continue

        # ---------------------------------------------------------
        # 7) URL PATH formatÄ±: /live/user/pass/
        # ---------------------------------------------------------
        if "http://" in l or "https://" in l:
            url = extract_url(l)
            if url:
                m = re.search(r"/live/([^/]+)/([^/]+)/", url)
                if m:
                    add(url, m.group(1), m.group(2))
                    i += 1
                    continue

        # ---------------------------------------------------------
        # 8) HOST + N kullanÄ±cÄ± formatÄ±
        # ---------------------------------------------------------
        if "http://" in l or "https://" in l:
            host = extract_url(l)
            if host:
                j = i + 1
                while j + 2 < L:
                    u = lines[j].strip()
                    p = lines[j+1].strip()
                    m = lines[j+2].strip()

                    if not u or not p:
                        break
                    try:
                        maxv = int(m)
                    except:
                        break

                    add(host, u, p, maxv)
                    j += 3

                i = j
                continue

        i += 1

    return out


# ============================================================
#  BÃ–LÃœM 10 â€” MAIN.PY Ä°Ã‡Ä°N VERÄ° YÃœKLEME
# ============================================================

def read_data():
    """Main.py iÃ§indeki lifespan iÃ§in Ã¼lke verisini RAM'e yÃ¼kler."""
    global COUNTRY_DISK_CACHE
    if os.path.exists(COUNTRY_DISK_FILE):
        try:
            with open(COUNTRY_DISK_FILE, "r", encoding="utf-8") as f:
                COUNTRY_DISK_CACHE = json.load(f)
                print(f"âœ… {len(COUNTRY_DISK_CACHE)} Ã¼lke verisi diskten yÃ¼klendi.")
        except Exception as e:
            print(f"âš ï¸ Ãœlke verisi okuma hatasÄ±: {e}")
    else:
        print("â„¹ï¸ Ãœlke cache dosyasÄ± henÃ¼z oluÅŸmamÄ±ÅŸ.")
